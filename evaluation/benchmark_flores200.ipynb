{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gwI0gleFnJW",
        "outputId": "1238b864-b681-4843-c7a5-caf3002d6a37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# 1. ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò\n",
        "!pip install -q transformers accelerate sacrebleu sentencepiece pandas tabulate huggingface_hub tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zCKalvXFsfv",
        "outputId": "810c3c50-3d04-4dfe-f71b-42eabcd00271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ GPU: Tesla T4\n",
            "üìä VRAM: 14.7 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import gc\n",
        "import time\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sacrebleu.metrics import CHRF, BLEU\n",
        "from tqdm import tqdm\n",
        "\n",
        "# GPU ÌôïÏù∏\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üìä VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è GPU ÏóÜÏùå\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "3ea537d77c9a4709ba62f809a6adf1f0",
            "fd87b9ccd0df49de830318f6e5ba93f5",
            "25d70272e2e34da4b53416a2dff10daf",
            "0d28217e666f40f3bc72f4d6f806ddd4",
            "f1f6940c74a9473fb3ba7aa9b98058a3",
            "ff2e22d26d5d4547a85c6ff37c20ca18",
            "644eb357da194edeb6f34a2603d87774",
            "daff65560c534b97ac5f32983f0251d0",
            "f3f13cd09808458b91685aa843316cd7",
            "83e5479c7aa84a1bbfce0db7f4666697",
            "405a584c3ad74441a96079f0a7a03025"
          ]
        },
        "id": "FdCMrjuYFtMo",
        "outputId": "925160ae-592a-4479-d310-5f03f7ba9240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Benchmark: 1012 samples, 1 models\n",
            "\n",
            "üîÑ Loading LFM2-v6.3-DPO-lora...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ea537d77c9a4709ba62f809a6adf1f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/22.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LFM2-v6.3-DPO-lora: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1012/1012 [16:38<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LFM2-v6.3-DPO-lora: CHrF++=31.46, BLEU=10.90\n",
            "\n",
            "==================================================\n",
            "üìà LEADERBOARD\n",
            "==================================================\n",
            "| Model              |   CHrF++ |    BLEU |\n",
            "|:-------------------|---------:|--------:|\n",
            "| LFM2-v6.3-DPO-lora |  31.4637 | 10.8952 |\n",
            "\n",
            "ÔøΩ Saved: benchmark_20251223_125719.csv\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_bead35cb-e89d-461d-89e5-4f4d20f21522\", \"benchmark_20251223_125719.csv\", 449753)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• ÏûêÎèô Îã§Ïö¥Î°úÎìú ÏãúÏûë!\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"LFM2 v4/v5/v6 Î≤§ÏπòÎßàÌÅ¨ + Î¨∏Ïû•Î≥Ñ Î∂ÑÏÑù (Colab ÏûêÎèô Îã§Ïö¥Î°úÎìú)\n",
        "ÎÖ∏Ìä∏Î∂Å ÏÖÄÏóê Î∂ôÏó¨ÎÑ£Í∏∞Ìï¥ÏÑú Î∞îÎ°ú Ïã§Ìñâ Í∞ÄÎä•\n",
        "\"\"\"\n",
        "\n",
        "#==============================================================================\n",
        "# üìå 1. ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò (ColabÏóêÏÑú ÏûêÎèô Ïã§Ìñâ)\n",
        "#==============================================================================\n",
        "import sys, subprocess, gc, time, os\n",
        "if \"google.colab\" in sys.modules:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                    \"transformers\", \"accelerate\", \"peft\", \"sacrebleu\", \"pandas\", \"tqdm\"])\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sacrebleu.metrics import CHRF, BLEU\n",
        "from tqdm import tqdm\n",
        "\n",
        "#==============================================================================\n",
        "# ÔøΩ 2. ÌÖåÏä§Ìä∏Ìï† Î™®Îç∏ ÏÑ§Ï†ï\n",
        "#==============================================================================\n",
        "MODELS_TO_TEST = [\n",
        "    # {\n",
        "    #     \"name\": \"LFM2-v6.3-DPO-Full\",\n",
        "    #     \"id\": \"gyung/lfm2-1.2b-koen-mt-v6.2-dpo\",\n",
        "    #     \"type\": \"transformers\"\n",
        "    # },\n",
        "    {\n",
        "          \"name\": \"LFM2-v6.3-DPO-lora\",\n",
        "          \"id\": \"gyung/lfm2-1.2b-koen-mt-v6.1-curriculum\",\n",
        "          \"type\": \"peft_adapter\",\n",
        "          \"adapter_id\": \"gyung/lfm2-1.2b-koen-mt-v6.3-dpo-lora\"\n",
        "    },\n",
        "    # {\n",
        "    #     \"name\": \"LFM2-v6.1-curriculum\",\n",
        "    #     \"id\": \"gyung/lfm2-1.2b-koen-mt-v6.1-curriculum\",\n",
        "    #     \"type\": \"transformers\"\n",
        "    # },\n",
        "    # {\n",
        "    #     \"name\": \"LFM2-v6-200k\",\n",
        "    #     \"id\": \"gyung/lfm2-1.2b-koen-mt-v6-sft-200k\",\n",
        "    #     \"type\": \"transformers\"\n",
        "    # },\n",
        "]\n",
        "\n",
        "#==============================================================================\n",
        "# üìå 3. Îç∞Ïù¥ÌÑ∞ÏÖã (Ïó¨Í∏∞Ïóê Îç∞Ïù¥ÌÑ∞ Î∂ôÏó¨ÎÑ£Í∏∞!)\n",
        "#==============================================================================\n",
        "# ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è ÏòÅÏñ¥ ÏõêÎ¨∏ Î¶¨Ïä§Ìä∏ (ENG_DATA) Ïó¨Í∏∞Ïóê Î∂ôÏó¨ÎÑ£Í∏∞ ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è\n",
        "# --- DATASET (Flores-200 DevTest : 1012 samples) ---\n",
        "\n",
        "ENG_DATA = []\n",
        "KOR_REF_DATA = []\n",
        "\n",
        "#==============================================================================\n",
        "# üìå 4. ÌïµÏã¨ Ìï®ÏàòÎì§ (ÏàòÏ†ï Î∂àÌïÑÏöî)\n",
        "#==============================================================================\n",
        "def generate(model, tokenizer, text):\n",
        "    msgs = [{\"role\": \"system\", \"content\": \"Translate the following text to Korean.\"},\n",
        "            {\"role\": \"user\", \"content\": text}]\n",
        "    ids = tokenizer.apply_chat_template(msgs, return_tensors=\"pt\", add_generation_prompt=True).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(ids, max_new_tokens=256, do_sample=True, temperature=0.3,\n",
        "                             min_p=0.15, repetition_penalty=1.05, pad_token_id=tokenizer.eos_token_id)\n",
        "    return tokenizer.decode(out[0][ids.shape[1]:], skip_special_tokens=True).strip()\n",
        "\n",
        "def sentence_scores(trans, refs):\n",
        "    chrf = CHRF()\n",
        "    return [round(chrf.sentence_score(t, [r]).score, 2) for t, r in zip(trans, refs)]\n",
        "\n",
        "def eval_model(info, srcs, refs):\n",
        "    print(f\"\\nüîÑ Loading {info['name']}...\")\n",
        "    tok = AutoTokenizer.from_pretrained(info[\"id\"])\n",
        "    if info[\"type\"] == \"peft_adapter\":\n",
        "        from peft import PeftModel\n",
        "        base = AutoModelForCausalLM.from_pretrained(info[\"id\"], device_map=\"auto\", torch_dtype=torch.float16)\n",
        "        model = PeftModel.from_pretrained(base, info[\"adapter_id\"]).merge_and_unload()\n",
        "    else:\n",
        "        model = AutoModelForCausalLM.from_pretrained(info[\"id\"], device_map=\"auto\", torch_dtype=torch.float16)\n",
        "\n",
        "    trans = [generate(model, tok, s) for s in tqdm(srcs, desc=info[\"name\"])]\n",
        "    chrf = CHRF().corpus_score(trans, [refs]).score\n",
        "    bleu = BLEU().corpus_score(trans, [refs]).score\n",
        "    scores = sentence_scores(trans, refs)\n",
        "\n",
        "    print(f\"‚úÖ {info['name']}: CHrF++={chrf:.2f}, BLEU={bleu:.2f}\")\n",
        "    del model, tok; torch.cuda.empty_cache(); gc.collect()\n",
        "    return {\"name\": info[\"name\"], \"chrf\": chrf, \"bleu\": bleu, \"trans\": trans, \"scores\": scores}\n",
        "\n",
        "#==============================================================================\n",
        "# üìå 5. Ïã§Ìñâ Î∞è ÏûêÎèô Îã§Ïö¥Î°úÎìú\n",
        "#==============================================================================\n",
        "print(f\"üìä Benchmark: {len(ENG_DATA)} samples, {len(MODELS_TO_TEST)} models\")\n",
        "results, data = [], {\"Source\": ENG_DATA, \"Reference\": KOR_REF_DATA}\n",
        "\n",
        "for m in MODELS_TO_TEST:\n",
        "    r = eval_model(m, ENG_DATA, KOR_REF_DATA)\n",
        "    results.append(r)\n",
        "    data[f\"Trans_{r['name']}\"] = r[\"trans\"]\n",
        "    data[f\"Score_{r['name']}\"] = r[\"scores\"]\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*50 + \"\\nüìà LEADERBOARD\\n\" + \"=\"*50)\n",
        "df_sum = pd.DataFrame([{\"Model\": r[\"name\"], \"CHrF++\": r[\"chrf\"], \"BLEU\": r[\"bleu\"]} for r in results])\n",
        "print(df_sum.sort_values(\"CHrF++\", ascending=False).to_markdown(index=False))\n",
        "\n",
        "# Save & Auto-download\n",
        "fname = f\"benchmark_{time.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "pd.DataFrame(data).to_csv(fname, index=False, encoding='utf-8-sig')\n",
        "print(f\"\\nÔøΩ Saved: {fname}\")\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import files\n",
        "    files.download(fname)\n",
        "    print(\"üì• ÏûêÎèô Îã§Ïö¥Î°úÎìú ÏãúÏûë!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44DWYJbjIY5z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d28217e666f40f3bc72f4d6f806ddd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83e5479c7aa84a1bbfce0db7f4666697",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_405a584c3ad74441a96079f0a7a03025",
            "value": "‚Äá22.2M/22.2M‚Äá[00:01&lt;00:00,‚Äá11.5MB/s]"
          }
        },
        "25d70272e2e34da4b53416a2dff10daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daff65560c534b97ac5f32983f0251d0",
            "max": 22240880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3f13cd09808458b91685aa843316cd7",
            "value": 22240880
          }
        },
        "3ea537d77c9a4709ba62f809a6adf1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd87b9ccd0df49de830318f6e5ba93f5",
              "IPY_MODEL_25d70272e2e34da4b53416a2dff10daf",
              "IPY_MODEL_0d28217e666f40f3bc72f4d6f806ddd4"
            ],
            "layout": "IPY_MODEL_f1f6940c74a9473fb3ba7aa9b98058a3"
          }
        },
        "405a584c3ad74441a96079f0a7a03025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "644eb357da194edeb6f34a2603d87774": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e5479c7aa84a1bbfce0db7f4666697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daff65560c534b97ac5f32983f0251d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f6940c74a9473fb3ba7aa9b98058a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f13cd09808458b91685aa843316cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd87b9ccd0df49de830318f6e5ba93f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff2e22d26d5d4547a85c6ff37c20ca18",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_644eb357da194edeb6f34a2603d87774",
            "value": "adapter_model.safetensors:‚Äá100%"
          }
        },
        "ff2e22d26d5d4547a85c6ff37c20ca18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
